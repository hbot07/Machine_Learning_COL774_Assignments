{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import cupy as np\n",
    "import sys\n",
    "import pdb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def get_data(x_path, y_path):\n",
    "    '''\n",
    "    Args:\n",
    "        x_path: path to x file\n",
    "        y_path: path to y file\n",
    "    Returns:\n",
    "        x: np array of [NUM_OF_SAMPLES x n]\n",
    "        y: np array of [NUM_OF_SAMPLES]\n",
    "    '''\n",
    "    x = np.load(x_path)\n",
    "    y = np.load(y_path)\n",
    "\n",
    "    x = x.astype('float')\n",
    "\n",
    "    #normalize each example in x to have 0 mean and 1 std\n",
    "\n",
    "    # Calculate the mean and standard deviation for each feature\n",
    "    feature_means = np.mean(x, axis=0)\n",
    "    feature_stds = np.std(x, axis=0)\n",
    "    feature_stds = feature_stds + (feature_stds == 0)\n",
    "\n",
    "    # Normalize each feature to have 0 mean and 1 std\n",
    "    x = (x - feature_means) / (feature_stds)\n",
    "\n",
    "    # Adjust labels to start from 0 if they start from 1\n",
    "    y = y - 1\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def get_metric(y_true, y_pred):\n",
    "    '''\n",
    "    Args:\n",
    "        y_true: np array of [NUM_SAMPLES x r] (one hot)\n",
    "                or np array of [NUM_SAMPLES]\n",
    "        y_pred: np array of [NUM_SAMPLES x r] (one hot)\n",
    "                or np array of [NUM_SAMPLES]\n",
    "\n",
    "    '''\n",
    "    results = classification_report(y_pred, y_true)\n",
    "    print(results)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T13:34:15.069700Z",
     "start_time": "2023-11-04T13:34:13.566503Z"
    },
    "id": "caeb9da8ee899ae"
   },
   "id": "caeb9da8ee899ae"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((10000, 1024), (10000,), (1000, 1024), (1000,))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "x_test, y_test = get_data('x_test.npy', 'y_test.npy')\n",
    "x_train, y_train = get_data('x_train.npy', 'y_train.npy')\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T13:34:15.389647Z",
     "start_time": "2023-11-04T13:34:15.073309Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d92553baff72547d",
    "outputId": "45790ab7-56aa-4771-8b5b-59a5394d29c3"
   },
   "id": "d92553baff72547d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "label_encoder = OneHotEncoder(sparse_output = False)\n",
    "label_encoder.fit(np.expand_dims(y_train, axis = -1).get())\n",
    "\n",
    "y_train_onehot = np.asarray(label_encoder.transform(np.expand_dims(y_train, axis = -1).get()))\n",
    "y_test_onehot = np.asarray(label_encoder.transform(np.expand_dims(y_test, axis = -1).get()))"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T13:34:22.739639Z",
     "start_time": "2023-11-04T13:34:22.728551Z"
    },
    "id": "2bdaeadda38be13e"
   },
   "id": "2bdaeadda38be13e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.20565902],\n",
       "       [0.19788553],\n",
       "       [0.19395291],\n",
       "       [0.19847146],\n",
       "       [0.20403108]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.activations = []\n",
    "\n",
    "        # Initialize weights and biases for each layer\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            # Weights are initialized with small random values\n",
    "            self.weights.append(np.random.randn(layer_sizes[i+1], layer_sizes[i]) * 0.01)\n",
    "            self.biases.append(np.zeros((layer_sizes[i+1], 1)))\n",
    "\n",
    "    def relu(self, z):\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    def relu_derivative(self, z):\n",
    "        return (z > 0).astype(float)\n",
    "\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        \n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def softmax(self, z):\n",
    "        \n",
    "        e_z = np.exp(z)\n",
    "        return e_z / e_z.sum(axis=0, keepdims=True)\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        activation = x\n",
    "        self.activations = [x]  \n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(w, activation) + b\n",
    "            activation = self.relu(z) if w is not self.weights[-1] else self.softmax(z)\n",
    "            self.activations.append(activation)\n",
    "\n",
    "        return self.activations[-1]"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T15:22:29.380857Z",
     "start_time": "2023-11-04T15:22:29.367477Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "839aebbd1796dc2e",
    "outputId": "35cf1f53-139d-478a-fd4e-23d11be6657a"
   },
   "id": "839aebbd1796dc2e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def cross_entropy_loss(self, y_pred, y_true):\n",
    "        m = y_true.shape[1] \n",
    "        loss = -np.sum(y_true * np.log(y_pred)) / m\n",
    "        return loss\n",
    "\n",
    "    def backpropagation(self, y_true):\n",
    "        m = y_true.shape[1]  # Number of examples\n",
    "        y_pred = self.activations[-1]  # The output of the last layer\n",
    "        y_true = y_true.reshape(y_pred.shape)\n",
    "\n",
    "        d_weights = [np.zeros(w.shape) for w in self.weights]\n",
    "        d_biases = [np.zeros(b.shape) for b in self.biases]\n",
    "\n",
    "        # Calculate derivative of loss w.r.t. the last layer output\n",
    "        d_loss = y_pred - y_true\n",
    "\n",
    "        for i in reversed(range(len(d_weights))):\n",
    "            d_activations = d_loss * self.relu_derivative(self.activations[i+1]) if i != len(d_weights) - 1 else d_loss\n",
    "            d_weights[i] = np.dot(d_activations, self.activations[i].T) / m\n",
    "            d_biases[i] = np.sum(d_activations, axis=1, keepdims=True) / m\n",
    "            if i != 0:\n",
    "                d_loss = np.dot(self.weights[i].T, d_activations)\n",
    "\n",
    "        return d_weights, d_biases\n",
    "\n",
    "    def sigmoid_derivative(self, s):\n",
    "        return s * (1 - s)\n",
    "\n",
    "    def update_parameters(self, d_weights, d_biases, learning_rate):\n",
    "        \"\"\"\n",
    "        Updates the parameters using the computed gradients.\n",
    "        \"\"\"\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= learning_rate * d_weights[i]\n",
    "            self.biases[i] -= learning_rate * d_biases[i]\n",
    "\n",
    "    def train(self, x_train, y_train, epochs, mini_batch_size, learning_rate, conv_threshold = 0.001, conv_epochs = 5):\n",
    "        n = x_train.shape[1]\n",
    "\n",
    "        loss_history = []\n",
    "        permutation = np.random.permutation(n)\n",
    "        for epoch in range(epochs):\n",
    "            x_train_shuffled = x_train[:, permutation]\n",
    "            y_train_shuffled = y_train[:, permutation]\n",
    "\n",
    "            for k in range(0, n, mini_batch_size):\n",
    "                mini_batch_x = x_train_shuffled[:, k:k + mini_batch_size]\n",
    "                mini_batch_y = y_train_shuffled[:, k:k + mini_batch_size]\n",
    "                # Forward pass\n",
    "                self.feedforward(mini_batch_x)\n",
    "                # Backward pass\n",
    "                d_weights, d_biases = self.backpropagation(mini_batch_y)\n",
    "                # Update parameters\n",
    "                self.update_parameters(d_weights, d_biases, learning_rate)\n",
    "\n",
    "            loss = self.cross_entropy_loss(self.feedforward(x_train), y_train)\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "            loss_history.append(loss)\n",
    "\n",
    "            if len(loss_history) > conv_epochs:\n",
    "                temp = loss_history[-conv_epochs:]\n",
    "                if np.std(temp) < conv_threshold:\n",
    "                    print('Converged')\n",
    "                    break"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T15:22:32.158434Z",
     "start_time": "2023-11-04T15:22:32.156680Z"
    },
    "id": "15ad70a12f16b147"
   },
   "id": "15ad70a12f16b147"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def train_c(self, x_train, y_train, epochs, mini_batch_size, learning_rate, conv_threshold = 0.001, conv_epochs = 5):\n",
    "        n = x_train.shape[1]  \n",
    "        loss_history = []\n",
    "        permutation = np.random.permutation(n)\n",
    "        learning_rate_c = learning_rate\n",
    "        for epoch in range(epochs):\n",
    "            learning_rate = learning_rate_c / pow(epoch+1, 0.5)\n",
    "            x_train_shuffled = x_train[:, permutation]\n",
    "            y_train_shuffled = y_train[:, permutation]\n",
    "\n",
    "            for k in range(0, n, mini_batch_size):\n",
    "                mini_batch_x = x_train_shuffled[:, k:k + mini_batch_size]\n",
    "                mini_batch_y = y_train_shuffled[:, k:k + mini_batch_size]\n",
    "                # Forward pass\n",
    "                self.feedforward(mini_batch_x)\n",
    "                # Backward pass\n",
    "                d_weights, d_biases = self.backpropagation(mini_batch_y)\n",
    "                # Update parameters\n",
    "                self.update_parameters(d_weights, d_biases, learning_rate)\n",
    "\n",
    "            loss = self.cross_entropy_loss(self.feedforward(x_train), y_train)\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "            loss_history.append(float(loss))\n",
    "\n",
    "            if len(loss_history) > conv_epochs:\n",
    "                temp = loss_history[-conv_epochs:]\n",
    "                if statistics.stdev(temp) < conv_threshold:\n",
    "                    print('Converged')\n",
    "                    break"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T15:22:36.150882Z",
     "start_time": "2023-11-04T15:22:36.143453Z"
    },
    "id": "4afa85796ad6feab"
   },
   "id": "4afa85796ad6feab"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "layer: [1024, 512, 5]\n",
      "Epoch 1/200, Loss: 0.8422\n",
      "Epoch 2/200, Loss: 0.6864\n",
      "Epoch 3/200, Loss: 0.6038\n",
      "Epoch 4/200, Loss: 0.5513\n",
      "Epoch 5/200, Loss: 0.5141\n",
      "Epoch 6/200, Loss: 0.4857\n",
      "Epoch 7/200, Loss: 0.4631\n",
      "Epoch 8/200, Loss: 0.4445\n",
      "Epoch 9/200, Loss: 0.4289\n",
      "Epoch 10/200, Loss: 0.4154\n",
      "Epoch 11/200, Loss: 0.4037\n",
      "Epoch 12/200, Loss: 0.3933\n",
      "Epoch 13/200, Loss: 0.3840\n",
      "Epoch 14/200, Loss: 0.3756\n",
      "Epoch 15/200, Loss: 0.3679\n",
      "Epoch 16/200, Loss: 0.3608\n",
      "Epoch 17/200, Loss: 0.3543\n",
      "Epoch 18/200, Loss: 0.3482\n",
      "Epoch 19/200, Loss: 0.3426\n",
      "Epoch 20/200, Loss: 0.3373\n",
      "Epoch 21/200, Loss: 0.3323\n",
      "Epoch 22/200, Loss: 0.3276\n",
      "Epoch 23/200, Loss: 0.3231\n",
      "Epoch 24/200, Loss: 0.3189\n",
      "Epoch 25/200, Loss: 0.3148\n",
      "Epoch 26/200, Loss: 0.3110\n",
      "Epoch 27/200, Loss: 0.3073\n",
      "Epoch 28/200, Loss: 0.3037\n",
      "Epoch 29/200, Loss: 0.3003\n",
      "Epoch 30/200, Loss: 0.2970\n",
      "Epoch 31/200, Loss: 0.2939\n",
      "Epoch 32/200, Loss: 0.2908\n",
      "Epoch 33/200, Loss: 0.2879\n",
      "Epoch 34/200, Loss: 0.2850\n",
      "Epoch 35/200, Loss: 0.2822\n",
      "Epoch 36/200, Loss: 0.2796\n",
      "Epoch 37/200, Loss: 0.2770\n",
      "Epoch 38/200, Loss: 0.2744\n",
      "Epoch 39/200, Loss: 0.2720\n",
      "Epoch 40/200, Loss: 0.2696\n",
      "Epoch 41/200, Loss: 0.2672\n",
      "Epoch 42/200, Loss: 0.2649\n",
      "Epoch 43/200, Loss: 0.2627\n",
      "Epoch 44/200, Loss: 0.2605\n",
      "Epoch 45/200, Loss: 0.2584\n",
      "Epoch 46/200, Loss: 0.2563\n",
      "Epoch 47/200, Loss: 0.2543\n",
      "Epoch 48/200, Loss: 0.2523\n",
      "Epoch 49/200, Loss: 0.2504\n",
      "Epoch 50/200, Loss: 0.2485\n",
      "Epoch 51/200, Loss: 0.2466\n",
      "Epoch 52/200, Loss: 0.2448\n",
      "Epoch 53/200, Loss: 0.2430\n",
      "Epoch 54/200, Loss: 0.2412\n",
      "Epoch 55/200, Loss: 0.2395\n",
      "Epoch 56/200, Loss: 0.2377\n",
      "Epoch 57/200, Loss: 0.2361\n",
      "Epoch 58/200, Loss: 0.2344\n",
      "Epoch 59/200, Loss: 0.2328\n",
      "Epoch 60/200, Loss: 0.2312\n",
      "Epoch 61/200, Loss: 0.2296\n",
      "Epoch 62/200, Loss: 0.2281\n",
      "Epoch 63/200, Loss: 0.2266\n",
      "Epoch 64/200, Loss: 0.2251\n",
      "Epoch 65/200, Loss: 0.2236\n",
      "Epoch 66/200, Loss: 0.2222\n",
      "Epoch 67/200, Loss: 0.2207\n",
      "Epoch 68/200, Loss: 0.2193\n",
      "Epoch 69/200, Loss: 0.2179\n",
      "Epoch 70/200, Loss: 0.2165\n",
      "Epoch 71/200, Loss: 0.2152\n",
      "Epoch 72/200, Loss: 0.2139\n",
      "Epoch 73/200, Loss: 0.2125\n",
      "Epoch 74/200, Loss: 0.2112\n",
      "Epoch 75/200, Loss: 0.2100\n",
      "Epoch 76/200, Loss: 0.2087\n",
      "Epoch 77/200, Loss: 0.2074\n",
      "Epoch 78/200, Loss: 0.2062\n",
      "Epoch 79/200, Loss: 0.2050\n",
      "Epoch 80/200, Loss: 0.2038\n",
      "Epoch 81/200, Loss: 0.2026\n",
      "Epoch 82/200, Loss: 0.2014\n",
      "Epoch 83/200, Loss: 0.2003\n",
      "Epoch 84/200, Loss: 0.1991\n",
      "Epoch 85/200, Loss: 0.1980\n",
      "Epoch 86/200, Loss: 0.1969\n",
      "Epoch 87/200, Loss: 0.1958\n",
      "Epoch 88/200, Loss: 0.1947\n",
      "Epoch 89/200, Loss: 0.1936\n",
      "Epoch 90/200, Loss: 0.1925\n",
      "Epoch 91/200, Loss: 0.1914\n",
      "Epoch 92/200, Loss: 0.1904\n",
      "Epoch 93/200, Loss: 0.1894\n",
      "Epoch 94/200, Loss: 0.1883\n",
      "Epoch 95/200, Loss: 0.1873\n",
      "Epoch 96/200, Loss: 0.1863\n",
      "Epoch 97/200, Loss: 0.1853\n",
      "Epoch 98/200, Loss: 0.1844\n",
      "Epoch 99/200, Loss: 0.1834\n",
      "Epoch 100/200, Loss: 0.1824\n",
      "Epoch 101/200, Loss: 0.1815\n",
      "Epoch 102/200, Loss: 0.1805\n",
      "Epoch 103/200, Loss: 0.1796\n",
      "Epoch 104/200, Loss: 0.1787\n",
      "Epoch 105/200, Loss: 0.1777\n",
      "Epoch 106/200, Loss: 0.1768\n",
      "Epoch 107/200, Loss: 0.1759\n",
      "Epoch 108/200, Loss: 0.1750\n",
      "Epoch 109/200, Loss: 0.1742\n",
      "Epoch 110/200, Loss: 0.1733\n",
      "Epoch 111/200, Loss: 0.1724\n",
      "Epoch 112/200, Loss: 0.1716\n",
      "Epoch 113/200, Loss: 0.1707\n",
      "Epoch 114/200, Loss: 0.1699\n",
      "Epoch 115/200, Loss: 0.1690\n",
      "Epoch 116/200, Loss: 0.1682\n",
      "Epoch 117/200, Loss: 0.1674\n",
      "Epoch 118/200, Loss: 0.1666\n",
      "Epoch 119/200, Loss: 0.1658\n",
      "Epoch 120/200, Loss: 0.1650\n",
      "Epoch 121/200, Loss: 0.1642\n",
      "Epoch 122/200, Loss: 0.1634\n",
      "Epoch 123/200, Loss: 0.1626\n",
      "Epoch 124/200, Loss: 0.1619\n",
      "Epoch 125/200, Loss: 0.1611\n",
      "Epoch 126/200, Loss: 0.1604\n",
      "Epoch 127/200, Loss: 0.1596\n",
      "Epoch 128/200, Loss: 0.1589\n",
      "Epoch 129/200, Loss: 0.1581\n",
      "Epoch 130/200, Loss: 0.1574\n",
      "Epoch 131/200, Loss: 0.1567\n",
      "Epoch 132/200, Loss: 0.1559\n",
      "Epoch 133/200, Loss: 0.1552\n",
      "Epoch 134/200, Loss: 0.1545\n",
      "Epoch 135/200, Loss: 0.1538\n",
      "Epoch 136/200, Loss: 0.1531\n",
      "Epoch 137/200, Loss: 0.1524\n",
      "Epoch 138/200, Loss: 0.1517\n",
      "Epoch 139/200, Loss: 0.1511\n",
      "Epoch 140/200, Loss: 0.1504\n",
      "Epoch 141/200, Loss: 0.1497\n",
      "Epoch 142/200, Loss: 0.1491\n",
      "Epoch 143/200, Loss: 0.1484\n",
      "Epoch 144/200, Loss: 0.1477\n",
      "Epoch 145/200, Loss: 0.1471\n",
      "Epoch 146/200, Loss: 0.1464\n",
      "Epoch 147/200, Loss: 0.1458\n",
      "Epoch 148/200, Loss: 0.1452\n",
      "Epoch 149/200, Loss: 0.1445\n",
      "Epoch 150/200, Loss: 0.1439\n",
      "Epoch 151/200, Loss: 0.1433\n",
      "Converged\n",
      "layer: [1024, 512, 256, 5]\n",
      "Epoch 1/200, Loss: 1.5000\n",
      "Epoch 2/200, Loss: 1.0618\n",
      "Epoch 3/200, Loss: 0.9277\n",
      "Epoch 4/200, Loss: 0.8536\n",
      "Epoch 5/200, Loss: 0.7912\n",
      "Epoch 6/200, Loss: 0.7328\n",
      "Epoch 7/200, Loss: 0.6773\n",
      "Epoch 8/200, Loss: 0.6264\n",
      "Epoch 9/200, Loss: 0.5816\n",
      "Epoch 10/200, Loss: 0.5432\n",
      "Epoch 11/200, Loss: 0.5105\n",
      "Epoch 12/200, Loss: 0.4825\n",
      "Epoch 13/200, Loss: 0.4583\n",
      "Epoch 14/200, Loss: 0.4372\n",
      "Epoch 15/200, Loss: 0.4187\n",
      "Epoch 16/200, Loss: 0.4023\n",
      "Epoch 17/200, Loss: 0.3877\n",
      "Epoch 18/200, Loss: 0.3746\n",
      "Epoch 19/200, Loss: 0.3628\n",
      "Epoch 20/200, Loss: 0.3521\n",
      "Epoch 21/200, Loss: 0.3423\n",
      "Epoch 22/200, Loss: 0.3332\n",
      "Epoch 23/200, Loss: 0.3249\n",
      "Epoch 24/200, Loss: 0.3171\n",
      "Epoch 25/200, Loss: 0.3099\n",
      "Epoch 26/200, Loss: 0.3031\n",
      "Epoch 27/200, Loss: 0.2967\n",
      "Epoch 28/200, Loss: 0.2906\n",
      "Epoch 29/200, Loss: 0.2849\n",
      "Epoch 30/200, Loss: 0.2794\n",
      "Epoch 31/200, Loss: 0.2742\n",
      "Epoch 32/200, Loss: 0.2692\n",
      "Epoch 33/200, Loss: 0.2644\n",
      "Epoch 34/200, Loss: 0.2598\n",
      "Epoch 35/200, Loss: 0.2554\n",
      "Epoch 36/200, Loss: 0.2511\n",
      "Epoch 37/200, Loss: 0.2470\n",
      "Epoch 38/200, Loss: 0.2430\n",
      "Epoch 39/200, Loss: 0.2391\n",
      "Epoch 40/200, Loss: 0.2354\n",
      "Epoch 41/200, Loss: 0.2317\n",
      "Epoch 42/200, Loss: 0.2282\n",
      "Epoch 43/200, Loss: 0.2247\n",
      "Epoch 44/200, Loss: 0.2214\n",
      "Epoch 45/200, Loss: 0.2181\n",
      "Epoch 46/200, Loss: 0.2149\n",
      "Epoch 47/200, Loss: 0.2118\n",
      "Epoch 48/200, Loss: 0.2088\n",
      "Epoch 49/200, Loss: 0.2058\n",
      "Epoch 50/200, Loss: 0.2029\n",
      "Epoch 51/200, Loss: 0.2001\n",
      "Epoch 52/200, Loss: 0.1973\n",
      "Epoch 53/200, Loss: 0.1946\n",
      "Epoch 54/200, Loss: 0.1920\n",
      "Epoch 55/200, Loss: 0.1894\n",
      "Epoch 56/200, Loss: 0.1868\n",
      "Epoch 57/200, Loss: 0.1843\n",
      "Epoch 58/200, Loss: 0.1818\n",
      "Epoch 59/200, Loss: 0.1794\n",
      "Epoch 60/200, Loss: 0.1770\n",
      "Epoch 61/200, Loss: 0.1747\n",
      "Epoch 62/200, Loss: 0.1724\n",
      "Epoch 63/200, Loss: 0.1702\n",
      "Epoch 64/200, Loss: 0.1680\n",
      "Epoch 65/200, Loss: 0.1658\n",
      "Epoch 66/200, Loss: 0.1636\n",
      "Epoch 67/200, Loss: 0.1616\n",
      "Epoch 68/200, Loss: 0.1595\n",
      "Epoch 69/200, Loss: 0.1575\n",
      "Epoch 70/200, Loss: 0.1555\n",
      "Epoch 71/200, Loss: 0.1535\n",
      "Epoch 72/200, Loss: 0.1516\n",
      "Epoch 73/200, Loss: 0.1497\n",
      "Epoch 74/200, Loss: 0.1478\n",
      "Epoch 75/200, Loss: 0.1460\n",
      "Epoch 76/200, Loss: 0.1441\n",
      "Epoch 77/200, Loss: 0.1424\n",
      "Epoch 78/200, Loss: 0.1406\n",
      "Epoch 79/200, Loss: 0.1389\n",
      "Epoch 80/200, Loss: 0.1372\n",
      "Epoch 81/200, Loss: 0.1355\n",
      "Epoch 82/200, Loss: 0.1338\n",
      "Epoch 83/200, Loss: 0.1322\n",
      "Epoch 84/200, Loss: 0.1306\n",
      "Epoch 85/200, Loss: 0.1290\n",
      "Epoch 86/200, Loss: 0.1274\n",
      "Epoch 87/200, Loss: 0.1259\n",
      "Epoch 88/200, Loss: 0.1244\n",
      "Epoch 89/200, Loss: 0.1229\n",
      "Epoch 90/200, Loss: 0.1214\n",
      "Epoch 91/200, Loss: 0.1199\n",
      "Epoch 92/200, Loss: 0.1185\n",
      "Epoch 93/200, Loss: 0.1171\n",
      "Epoch 94/200, Loss: 0.1157\n",
      "Epoch 95/200, Loss: 0.1143\n",
      "Epoch 96/200, Loss: 0.1130\n",
      "Epoch 97/200, Loss: 0.1117\n",
      "Epoch 98/200, Loss: 0.1104\n",
      "Epoch 99/200, Loss: 0.1091\n",
      "Epoch 100/200, Loss: 0.1078\n",
      "Epoch 101/200, Loss: 0.1066\n",
      "Epoch 102/200, Loss: 0.1053\n",
      "Epoch 103/200, Loss: 0.1041\n",
      "Epoch 104/200, Loss: 0.1029\n",
      "Epoch 105/200, Loss: 0.1017\n",
      "Epoch 106/200, Loss: 0.1006\n",
      "Epoch 107/200, Loss: 0.0994\n",
      "Epoch 108/200, Loss: 0.0983\n",
      "Epoch 109/200, Loss: 0.0972\n",
      "Epoch 110/200, Loss: 0.0961\n",
      "Epoch 111/200, Loss: 0.0950\n",
      "Epoch 112/200, Loss: 0.0939\n",
      "Epoch 113/200, Loss: 0.0929\n",
      "Epoch 114/200, Loss: 0.0918\n",
      "Epoch 115/200, Loss: 0.0908\n",
      "Epoch 116/200, Loss: 0.0898\n",
      "Epoch 117/200, Loss: 0.0888\n",
      "Epoch 118/200, Loss: 0.0878\n",
      "Epoch 119/200, Loss: 0.0869\n",
      "Epoch 120/200, Loss: 0.0859\n",
      "Epoch 121/200, Loss: 0.0850\n",
      "Epoch 122/200, Loss: 0.0841\n",
      "Epoch 123/200, Loss: 0.0832\n",
      "Epoch 124/200, Loss: 0.0823\n",
      "Epoch 125/200, Loss: 0.0814\n",
      "Epoch 126/200, Loss: 0.0805\n",
      "Epoch 127/200, Loss: 0.0797\n",
      "Epoch 128/200, Loss: 0.0788\n",
      "Epoch 129/200, Loss: 0.0780\n",
      "Epoch 130/200, Loss: 0.0772\n",
      "Epoch 131/200, Loss: 0.0764\n",
      "Epoch 132/200, Loss: 0.0756\n",
      "Epoch 133/200, Loss: 0.0748\n",
      "Epoch 134/200, Loss: 0.0740\n",
      "Epoch 135/200, Loss: 0.0733\n",
      "Epoch 136/200, Loss: 0.0725\n",
      "Epoch 137/200, Loss: 0.0718\n",
      "Epoch 138/200, Loss: 0.0710\n",
      "Epoch 139/200, Loss: 0.0703\n",
      "Epoch 140/200, Loss: 0.0696\n",
      "Epoch 141/200, Loss: 0.0689\n",
      "Epoch 142/200, Loss: 0.0682\n",
      "Epoch 143/200, Loss: 0.0675\n",
      "Epoch 144/200, Loss: 0.0669\n",
      "Epoch 145/200, Loss: 0.0662\n",
      "Epoch 146/200, Loss: 0.0655\n",
      "Epoch 147/200, Loss: 0.0649\n",
      "Epoch 148/200, Loss: 0.0643\n",
      "Epoch 149/200, Loss: 0.0636\n",
      "Epoch 150/200, Loss: 0.0630\n",
      "Converged\n",
      "layer: [1024, 512, 256, 128, 5]\n",
      "Epoch 1/200, Loss: 1.6090\n",
      "Epoch 2/200, Loss: 1.6088\n",
      "Epoch 3/200, Loss: 1.6086\n",
      "Epoch 4/200, Loss: 1.6083\n",
      "Epoch 5/200, Loss: 1.6080\n",
      "Epoch 6/200, Loss: 1.6076\n",
      "Converged\n",
      "layer: [1024, 512, 256, 128, 64, 5]\n",
      "Epoch 1/200, Loss: 1.6092\n",
      "Epoch 2/200, Loss: 1.6092\n",
      "Epoch 3/200, Loss: 1.6091\n",
      "Epoch 4/200, Loss: 1.6091\n",
      "Epoch 5/200, Loss: 1.6091\n",
      "Epoch 6/200, Loss: 1.6091\n",
      "Converged\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "y_train_one_hot = np.eye(5)[y_train].T\n",
    "\n",
    "hidden_layers = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]\n",
    "layers = [[1024] + hidden_layer + [5] for hidden_layer in hidden_layers]\n",
    "models_e = {}\n",
    "for layer in layers:\n",
    "    print(f'layer: {layer}')\n",
    "    nn = NeuralNetwork(layer)\n",
    "    nn.train_c(x_train.T, y_train_one_hot, epochs=200, mini_batch_size=32, learning_rate=0.01)\n",
    "    models_e[str(layer)] = nn"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T16:17:19.893847Z",
     "start_time": "2023-11-04T16:16:53.761453Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e405b4822b98cdc2",
    "outputId": "b0cc106a-e4bd-48a3-ad54-23c5583f5446"
   },
   "id": "e405b4822b98cdc2"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "layer: [1024, 512, 256, 128, 5]\n",
      "Epoch 1/200, Loss: 1.6090\n",
      "Epoch 2/200, Loss: 1.6088\n",
      "Epoch 3/200, Loss: 1.6086\n",
      "Epoch 4/200, Loss: 1.6083\n",
      "Epoch 5/200, Loss: 1.6080\n",
      "Epoch 6/200, Loss: 1.6076\n",
      "Epoch 7/200, Loss: 1.6071\n",
      "Epoch 8/200, Loss: 1.6063\n",
      "Epoch 9/200, Loss: 1.6053\n",
      "Epoch 10/200, Loss: 1.6037\n",
      "Epoch 11/200, Loss: 1.6014\n",
      "Epoch 12/200, Loss: 1.5977\n",
      "Epoch 13/200, Loss: 1.5916\n",
      "Epoch 14/200, Loss: 1.5806\n",
      "Epoch 15/200, Loss: 1.5587\n",
      "Epoch 16/200, Loss: 1.5107\n",
      "Epoch 17/200, Loss: 1.4132\n",
      "Epoch 18/200, Loss: 1.2985\n",
      "Epoch 19/200, Loss: 1.1810\n",
      "Epoch 20/200, Loss: 1.0713\n",
      "Epoch 21/200, Loss: 1.0064\n",
      "Epoch 22/200, Loss: 0.9630\n",
      "Epoch 23/200, Loss: 0.9296\n",
      "Epoch 24/200, Loss: 0.9007\n",
      "Epoch 25/200, Loss: 0.8737\n",
      "Epoch 26/200, Loss: 0.8471\n",
      "Epoch 27/200, Loss: 0.8217\n",
      "Epoch 28/200, Loss: 0.7969\n",
      "Epoch 29/200, Loss: 0.7728\n",
      "Epoch 30/200, Loss: 0.7490\n",
      "Epoch 31/200, Loss: 0.7254\n",
      "Epoch 32/200, Loss: 0.7018\n",
      "Epoch 33/200, Loss: 0.6779\n",
      "Epoch 34/200, Loss: 0.6539\n",
      "Epoch 35/200, Loss: 0.6295\n",
      "Epoch 36/200, Loss: 0.6049\n",
      "Epoch 37/200, Loss: 0.5802\n",
      "Epoch 38/200, Loss: 0.5557\n",
      "Epoch 39/200, Loss: 0.5319\n",
      "Epoch 40/200, Loss: 0.5090\n",
      "Epoch 41/200, Loss: 0.4873\n",
      "Epoch 42/200, Loss: 0.4668\n",
      "Epoch 43/200, Loss: 0.4477\n",
      "Epoch 44/200, Loss: 0.4298\n",
      "Epoch 45/200, Loss: 0.4132\n",
      "Epoch 46/200, Loss: 0.3979\n",
      "Epoch 47/200, Loss: 0.3837\n",
      "Epoch 48/200, Loss: 0.3704\n",
      "Epoch 49/200, Loss: 0.3581\n",
      "Epoch 50/200, Loss: 0.3466\n",
      "Epoch 51/200, Loss: 0.3358\n",
      "Epoch 52/200, Loss: 0.3257\n",
      "Epoch 53/200, Loss: 0.3161\n",
      "Epoch 54/200, Loss: 0.3071\n",
      "Epoch 55/200, Loss: 0.2985\n",
      "Epoch 56/200, Loss: 0.2904\n",
      "Epoch 57/200, Loss: 0.2827\n",
      "Epoch 58/200, Loss: 0.2753\n",
      "Epoch 59/200, Loss: 0.2683\n",
      "Epoch 60/200, Loss: 0.2615\n",
      "Epoch 61/200, Loss: 0.2550\n",
      "Epoch 62/200, Loss: 0.2488\n",
      "Epoch 63/200, Loss: 0.2428\n",
      "Epoch 64/200, Loss: 0.2369\n",
      "Epoch 65/200, Loss: 0.2313\n",
      "Epoch 66/200, Loss: 0.2259\n",
      "Epoch 67/200, Loss: 0.2206\n",
      "Epoch 68/200, Loss: 0.2155\n",
      "Epoch 69/200, Loss: 0.2106\n",
      "Epoch 70/200, Loss: 0.2058\n",
      "Epoch 71/200, Loss: 0.2011\n",
      "Epoch 72/200, Loss: 0.1966\n",
      "Epoch 73/200, Loss: 0.1922\n",
      "Epoch 74/200, Loss: 0.1879\n",
      "Epoch 75/200, Loss: 0.1837\n",
      "Epoch 76/200, Loss: 0.1796\n",
      "Epoch 77/200, Loss: 0.1756\n",
      "Epoch 78/200, Loss: 0.1717\n",
      "Epoch 79/200, Loss: 0.1678\n",
      "Epoch 80/200, Loss: 0.1641\n",
      "Epoch 81/200, Loss: 0.1604\n",
      "Epoch 82/200, Loss: 0.1569\n",
      "Epoch 83/200, Loss: 0.1533\n",
      "Epoch 84/200, Loss: 0.1499\n",
      "Epoch 85/200, Loss: 0.1466\n",
      "Epoch 86/200, Loss: 0.1433\n",
      "Epoch 87/200, Loss: 0.1401\n",
      "Epoch 88/200, Loss: 0.1369\n",
      "Epoch 89/200, Loss: 0.1338\n",
      "Epoch 90/200, Loss: 0.1308\n",
      "Epoch 91/200, Loss: 0.1279\n",
      "Epoch 92/200, Loss: 0.1250\n",
      "Epoch 93/200, Loss: 0.1222\n",
      "Epoch 94/200, Loss: 0.1194\n",
      "Epoch 95/200, Loss: 0.1167\n",
      "Epoch 96/200, Loss: 0.1141\n",
      "Epoch 97/200, Loss: 0.1115\n",
      "Epoch 98/200, Loss: 0.1090\n",
      "Epoch 99/200, Loss: 0.1065\n",
      "Epoch 100/200, Loss: 0.1041\n",
      "Epoch 101/200, Loss: 0.1017\n",
      "Epoch 102/200, Loss: 0.0994\n",
      "Epoch 103/200, Loss: 0.0972\n",
      "Epoch 104/200, Loss: 0.0950\n",
      "Epoch 105/200, Loss: 0.0928\n",
      "Epoch 106/200, Loss: 0.0907\n",
      "Epoch 107/200, Loss: 0.0887\n",
      "Epoch 108/200, Loss: 0.0867\n",
      "Epoch 109/200, Loss: 0.0847\n",
      "Epoch 110/200, Loss: 0.0828\n",
      "Epoch 111/200, Loss: 0.0810\n",
      "Epoch 112/200, Loss: 0.0791\n",
      "Epoch 113/200, Loss: 0.0774\n",
      "Epoch 114/200, Loss: 0.0757\n",
      "Epoch 115/200, Loss: 0.0740\n",
      "Epoch 116/200, Loss: 0.0724\n",
      "Epoch 117/200, Loss: 0.0708\n",
      "Epoch 118/200, Loss: 0.0692\n",
      "Epoch 119/200, Loss: 0.0677\n",
      "Epoch 120/200, Loss: 0.0662\n",
      "Epoch 121/200, Loss: 0.0648\n",
      "Epoch 122/200, Loss: 0.0634\n",
      "Epoch 123/200, Loss: 0.0620\n",
      "Epoch 124/200, Loss: 0.0607\n",
      "Epoch 125/200, Loss: 0.0594\n",
      "Epoch 126/200, Loss: 0.0581\n",
      "Epoch 127/200, Loss: 0.0569\n",
      "Epoch 128/200, Loss: 0.0557\n",
      "Epoch 129/200, Loss: 0.0545\n",
      "Epoch 130/200, Loss: 0.0534\n",
      "Epoch 131/200, Loss: 0.0523\n",
      "Epoch 132/200, Loss: 0.0512\n",
      "Epoch 133/200, Loss: 0.0502\n",
      "Epoch 134/200, Loss: 0.0492\n",
      "Epoch 135/200, Loss: 0.0482\n",
      "Epoch 136/200, Loss: 0.0473\n",
      "Epoch 137/200, Loss: 0.0463\n",
      "Epoch 138/200, Loss: 0.0454\n",
      "Epoch 139/200, Loss: 0.0445\n",
      "Epoch 140/200, Loss: 0.0437\n",
      "Epoch 141/200, Loss: 0.0429\n",
      "Epoch 142/200, Loss: 0.0421\n",
      "Epoch 143/200, Loss: 0.0413\n",
      "Epoch 144/200, Loss: 0.0405\n",
      "Epoch 145/200, Loss: 0.0398\n",
      "Epoch 146/200, Loss: 0.0391\n",
      "Epoch 147/200, Loss: 0.0384\n",
      "Epoch 148/200, Loss: 0.0377\n",
      "Epoch 149/200, Loss: 0.0370\n",
      "Epoch 150/200, Loss: 0.0364\n",
      "Epoch 151/200, Loss: 0.0357\n",
      "Epoch 152/200, Loss: 0.0351\n",
      "Epoch 153/200, Loss: 0.0345\n",
      "Epoch 154/200, Loss: 0.0340\n",
      "Epoch 155/200, Loss: 0.0334\n",
      "Epoch 156/200, Loss: 0.0329\n",
      "Epoch 157/200, Loss: 0.0323\n",
      "Epoch 158/200, Loss: 0.0318\n",
      "Epoch 159/200, Loss: 0.0313\n",
      "Epoch 160/200, Loss: 0.0308\n",
      "Epoch 161/200, Loss: 0.0304\n",
      "Epoch 162/200, Loss: 0.0299\n",
      "Epoch 163/200, Loss: 0.0294\n",
      "Epoch 164/200, Loss: 0.0290\n",
      "Epoch 165/200, Loss: 0.0286\n",
      "Epoch 166/200, Loss: 0.0281\n",
      "Epoch 167/200, Loss: 0.0277\n",
      "Epoch 168/200, Loss: 0.0273\n",
      "Epoch 169/200, Loss: 0.0270\n",
      "Epoch 170/200, Loss: 0.0266\n",
      "Epoch 171/200, Loss: 0.0262\n",
      "Epoch 172/200, Loss: 0.0258\n",
      "Epoch 173/200, Loss: 0.0255\n",
      "Epoch 174/200, Loss: 0.0252\n",
      "Epoch 175/200, Loss: 0.0248\n",
      "Epoch 176/200, Loss: 0.0245\n",
      "Epoch 177/200, Loss: 0.0242\n",
      "Epoch 178/200, Loss: 0.0239\n",
      "Epoch 179/200, Loss: 0.0236\n",
      "Epoch 180/200, Loss: 0.0233\n",
      "Epoch 181/200, Loss: 0.0230\n",
      "Epoch 182/200, Loss: 0.0227\n",
      "Epoch 183/200, Loss: 0.0224\n",
      "Epoch 184/200, Loss: 0.0221\n",
      "Epoch 185/200, Loss: 0.0219\n",
      "Epoch 186/200, Loss: 0.0216\n",
      "Epoch 187/200, Loss: 0.0213\n",
      "Epoch 188/200, Loss: 0.0211\n",
      "Epoch 189/200, Loss: 0.0208\n",
      "Epoch 190/200, Loss: 0.0206\n",
      "Epoch 191/200, Loss: 0.0204\n",
      "Epoch 192/200, Loss: 0.0201\n",
      "Epoch 193/200, Loss: 0.0199\n",
      "Epoch 194/200, Loss: 0.0197\n",
      "Epoch 195/200, Loss: 0.0195\n",
      "Epoch 196/200, Loss: 0.0193\n",
      "Epoch 197/200, Loss: 0.0191\n",
      "Epoch 198/200, Loss: 0.0189\n",
      "Epoch 199/200, Loss: 0.0187\n",
      "Epoch 200/200, Loss: 0.0185\n",
      "layer: [1024, 512, 256, 128, 64, 5]\n",
      "Epoch 1/200, Loss: 1.6092\n",
      "Epoch 2/200, Loss: 1.6092\n",
      "Epoch 3/200, Loss: 1.6091\n",
      "Epoch 4/200, Loss: 1.6091\n",
      "Epoch 5/200, Loss: 1.6091\n",
      "Epoch 6/200, Loss: 1.6091\n",
      "Epoch 7/200, Loss: 1.6091\n",
      "Epoch 8/200, Loss: 1.6091\n",
      "Epoch 9/200, Loss: 1.6091\n",
      "Epoch 10/200, Loss: 1.6091\n",
      "Epoch 11/200, Loss: 1.6091\n",
      "Epoch 12/200, Loss: 1.6091\n",
      "Converged\n"
     ]
    }
   ],
   "source": [
    "for layer in layers[-2:]:\n",
    "    print(f'layer: {layer}')\n",
    "    nn = NeuralNetwork(layer)\n",
    "    nn.train_c(x_train.T, y_train_one_hot, epochs=100, mini_batch_size=32, learning_rate=0.01, conv_threshold=1e-5, conv_epochs=10)\n",
    "    models_e[str(layer)] = nn"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T15:12:06.669944Z",
     "start_time": "2023-11-04T15:09:43.741898Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef9a9593a8c89cd3",
    "outputId": "0b718271-41bf-4c34-89dd-b3951454cf06"
   },
   "id": "ef9a9593a8c89cd3"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "layer: [1024, 512, 256, 128, 64, 5]\n",
      "Epoch 1/30, Loss: 1.6096\n",
      "Epoch 2/30, Loss: 1.6094\n",
      "Epoch 3/30, Loss: 1.6093\n",
      "Epoch 4/30, Loss: 1.6092\n",
      "Epoch 5/30, Loss: 1.6092\n",
      "Epoch 6/30, Loss: 1.6091\n",
      "Epoch 7/30, Loss: 1.6090\n",
      "Epoch 8/30, Loss: 1.6088\n",
      "Epoch 9/30, Loss: 1.6083\n",
      "Epoch 10/30, Loss: 1.6059\n",
      "Epoch 11/30, Loss: 1.5126\n",
      "Epoch 12/30, Loss: 0.9601\n",
      "Epoch 13/30, Loss: 0.5486\n",
      "Epoch 14/30, Loss: 0.3521\n",
      "Epoch 15/30, Loss: 0.2735\n",
      "Epoch 16/30, Loss: 0.2092\n",
      "Epoch 17/30, Loss: 0.1991\n",
      "Epoch 18/30, Loss: 0.1548\n",
      "Epoch 19/30, Loss: 0.1741\n",
      "Epoch 20/30, Loss: 0.1891\n",
      "Epoch 21/30, Loss: 0.1574\n",
      "Epoch 22/30, Loss: 0.4083\n",
      "Epoch 23/30, Loss: 0.0450\n",
      "Epoch 24/30, Loss: 0.0308\n",
      "Epoch 25/30, Loss: 0.0440\n",
      "Epoch 26/30, Loss: 0.0559\n",
      "Epoch 27/30, Loss: 0.0704\n",
      "Epoch 28/30, Loss: 0.0291\n",
      "Epoch 29/30, Loss: 0.0135\n",
      "Epoch 30/30, Loss: 0.0159\n"
     ]
    }
   ],
   "source": [
    "layer = layers[-1]\n",
    "print(f'layer: {layer}')\n",
    "nn = NeuralNetwork(layer)\n",
    "nn.train_c(x_train.T, y_train_one_hot, epochs=30, mini_batch_size=32, learning_rate=0.1, conv_threshold=1e-5, conv_epochs=20)\n",
    "models_e[str(layer)] = nn"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T16:14:27.601260Z",
     "start_time": "2023-11-04T16:14:19.691200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8d02f07498399fc",
    "outputId": "bd1b7e7d-8e3b-4df8-db53-b21d881b996f"
   },
   "id": "d8d02f07498399fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save models\n",
    "import pickle\n",
    "\n",
    "with open('pickles/models_e.pickle', 'wb') as handle:\n",
    "    pickle.dump(models_e, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T13:46:26.919139Z",
     "start_time": "2023-11-04T13:46:26.598689Z"
    },
    "id": "1ed8f4bd1d247cdf"
   },
   "id": "1ed8f4bd1d247cdf"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1024, 512, 5] hidden layer size\n",
      "Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1980\n",
      "           1       0.97      0.97      0.97      1984\n",
      "           2       0.94      0.95      0.95      1924\n",
      "           3       0.94      0.94      0.94      2025\n",
      "           4       0.97      0.97      0.97      2087\n",
      "\n",
      "    accuracy                           0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       224\n",
      "           1       0.87      0.93      0.90       187\n",
      "           2       0.79      0.83      0.81       190\n",
      "           3       0.73      0.72      0.72       189\n",
      "           4       0.90      0.80      0.85       210\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.85      0.85      0.85      1000\n",
      "weighted avg       0.86      0.86      0.86      1000\n",
      "\n",
      "[1024, 512, 256, 5] hidden layer size\n",
      "Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1977\n",
      "           1       0.99      0.99      0.99      1985\n",
      "           2       0.98      0.99      0.98      1934\n",
      "           3       0.99      0.98      0.98      2013\n",
      "           4       1.00      1.00      1.00      2091\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       224\n",
      "           1       0.88      0.94      0.91       186\n",
      "           2       0.84      0.86      0.85       195\n",
      "           3       0.80      0.77      0.79       194\n",
      "           4       0.90      0.84      0.87       201\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.88      0.88      0.88      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "[1024, 512, 256, 128, 5] hidden layer size\n",
      "Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1971\n",
      "           1       1.00      1.00      1.00      1980\n",
      "           2       1.00      1.00      1.00      1950\n",
      "           3       1.00      1.00      1.00      2002\n",
      "           4       1.00      1.00      1.00      2097\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       229\n",
      "           1       0.90      0.98      0.94       183\n",
      "           2       0.86      0.87      0.87       196\n",
      "           3       0.80      0.79      0.79       188\n",
      "           4       0.92      0.84      0.88       204\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "[1024, 512, 256, 128, 64, 5] hidden layer size\n",
      "Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1971\n",
      "           1       1.00      1.00      1.00      1976\n",
      "           2       1.00      1.00      1.00      1951\n",
      "           3       0.99      1.00      0.99      1987\n",
      "           4       1.00      0.99      0.99      2115\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       227\n",
      "           1       0.95      0.96      0.95       196\n",
      "           2       0.84      0.91      0.87       183\n",
      "           3       0.74      0.79      0.76       174\n",
      "           4       0.94      0.80      0.86       220\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n"
     ]
    }
   ],
   "source": [
    "# report results\n",
    "for layer in layers:\n",
    "    nn = models_e[str(layer)]\n",
    "    y_train_pred = np.argmax(nn.feedforward(x_train.T), axis=0)\n",
    "    y_test_pred = np.argmax(nn.feedforward(x_test.T), axis=0)\n",
    "    results = classification_report(y_train_pred.get(), y_train.get())\n",
    "    print(f\"{layer} hidden layer size\")\n",
    "    print('Training')\n",
    "    print(results)\n",
    "\n",
    "    results = classification_report(y_test_pred.get(), y_test.get())\n",
    "    print('Test')\n",
    "    print(results)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-04T13:46:27.409862Z",
     "start_time": "2023-11-04T13:46:26.897258Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2388e4f84d9812fa",
    "outputId": "03bda16a-0311-4ff9-bb61-8fb003154536"
   },
   "id": "2388e4f84d9812fa"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "avg_f1_scores_training = []\n",
    "avg_f1_scores_test = []\n",
    "for layer in layers:\n",
    "    nn = models_e[str(layer)]\n",
    "    y_train_pred = np.argmax(nn.feedforward(x_train.T), axis=0)\n",
    "    y_test_pred = np.argmax(nn.feedforward(x_test.T), axis=0)\n",
    "    results = classification_report(y_train_pred.get(), y_train.get(), output_dict=True)\n",
    "    avg_f1_scores_training.append(results['weighted avg']['f1-score'])\n",
    "\n",
    "    results = classification_report(y_test_pred.get(), y_test.get(), output_dict=True)\n",
    "    avg_f1_scores_test.append(results['weighted avg']['f1-score'])\n",
    "\n",
    "plt.plot([len(layer) for layer in layers], avg_f1_scores_training, label = 'Training')\n",
    "plt.plot([len(layer) for layer in layers], avg_f1_scores_test, label = 'Test')\n",
    "plt.xlabel('Hidden Layers Depth')\n",
    "plt.ylabel('Average F1 Score')\n",
    "plt.legend()\n",
    "plt.savefig('(e) relu adaptive training f1 vs hidden_depth.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-04T13:46:27.913749Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "3baa6aa5e40f560e",
    "outputId": "0e12e650-fc2b-4cf0-fb00-4fdafef09ecd"
   },
   "id": "3baa6aa5e40f560e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "d3d01210aa9b4c89"
   },
   "id": "d3d01210aa9b4c89"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
